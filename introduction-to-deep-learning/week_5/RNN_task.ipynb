{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "RNN-task.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLOZS_dfbAbl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7d74c688-5295-4ab0-db94-1080d8ab36c8"
      },
      "source": [
        "# set tf 1.x for colab\n",
        "%tensorflow_version 1.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ec2kqohfCdH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "d1101df1-eb86-416a-f0f7-9df4501b171f"
      },
      "source": [
        "! shred -u setup_google_colab.py\n",
        "! wget https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py -O setup_google_colab.py\n",
        "import setup_google_colab\n",
        "# please, uncomment the week you're working on\n",
        "# setup_google_colab.setup_week1()\n",
        "# setup_google_colab.setup_week2()\n",
        "# setup_google_colab.setup_week2_honor()\n",
        "# setup_google_colab.setup_week3()\n",
        "# setup_google_colab.setup_week4()\n",
        "setup_google_colab.setup_week5()\n",
        "# setup_google_colab.setup_week6()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shred: setup_google_colab.py: failed to open for writing: No such file or directory\n",
            "--2020-06-09 05:10:27--  https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3636 (3.6K) [text/plain]\n",
            "Saving to: ‘setup_google_colab.py’\n",
            "\n",
            "setup_google_colab. 100%[===================>]   3.55K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-06-09 05:10:27 (41.9 MB/s) - ‘setup_google_colab.py’ saved [3636/3636]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0RL1jDBbAbr",
        "colab_type": "text"
      },
      "source": [
        "# Generating names with recurrent neural networks\n",
        "\n",
        "This time you'll find yourself delving into the heart (and other intestines) of recurrent neural networks on a class of toy problems.\n",
        "\n",
        "Struggle to find a name for the variable? Let's see how you'll come up with a name for your son/daughter. Surely no human has expertize over what is a good child name, so let us train RNN instead;\n",
        "\n",
        "It's dangerous to go alone, take these:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.696201Z",
          "start_time": "2018-08-13T20:26:38.104103Z"
        },
        "id": "HQ1OzU43bAbs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0f3f557e-0036-4771-fec8-0553067911e0"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import os\n",
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "import keras_utils\n",
        "import tqdm_utils"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOC3g-dYbAbw",
        "colab_type": "text"
      },
      "source": [
        "# Load data\n",
        "The dataset contains ~8k earthling names from different cultures, all in latin transcript.\n",
        "\n",
        "This notebook has been designed so as to allow you to quickly swap names for something similar: deep learning article titles, IKEA furniture, pokemon names, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.701832Z",
          "start_time": "2018-08-13T20:26:42.697766Z"
        },
        "id": "uMfYsR0AbAbx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "start_token = \" \"  # so that the network knows that we're generating a first token\n",
        "\n",
        "# this is the token for padding,\n",
        "# we will add fake pad token at the end of names \n",
        "# to make them of equal size for further batching\n",
        "pad_token = \"#\"\n",
        "\n",
        "with open(\"names\") as f:\n",
        "    names = f.read()[:-1].split('\\n')\n",
        "    names = [start_token + name for name in names]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.707885Z",
          "start_time": "2018-08-13T20:26:42.703302Z"
        },
        "id": "7bqWx_rebAb1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "c9936713-4514-4004-da67-29128265d4d2"
      },
      "source": [
        "print('number of samples:', len(names))\n",
        "for x in names[::1000]:\n",
        "    print(x)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of samples: 7944\n",
            " Abagael\n",
            " Claresta\n",
            " Glory\n",
            " Liliane\n",
            " Prissie\n",
            " Geeta\n",
            " Giovanne\n",
            " Piggy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.857411Z",
          "start_time": "2018-08-13T20:26:42.709371Z"
        },
        "id": "oG2F84Z8bAb4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "a8ad8d70-ab95-4ca3-b4e8-99bdf16540da"
      },
      "source": [
        "MAX_LENGTH = max(map(len, names))\n",
        "print(\"max length:\", MAX_LENGTH)\n",
        "\n",
        "plt.title('Sequence length distribution')\n",
        "plt.hist(list(map(len, names)), bins=25);"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max length: 16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FfrVcuibAb9",
        "colab_type": "text"
      },
      "source": [
        "# Text processing\n",
        "\n",
        "First we need to collect a \"vocabulary\" of all unique tokens i.e. unique characters. We can then encode inputs as a sequence of character ids."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.864592Z",
          "start_time": "2018-08-13T20:26:42.858725Z"
        },
        "id": "jdht5pHwbAb-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "d15df55c-cb3e-4723-9a9e-24cfdb414b30"
      },
      "source": [
        "tokens = set(''.join(names)) ### YOUR CODE HERE: all unique characters go here, padding included!\n",
        "tokens.add(pad_token)\n",
        "tokens = list(tokens)\n",
        "n_tokens = len(tokens)\n",
        "print(tokens)\n",
        "print ('n_tokens:', n_tokens)\n",
        "\n",
        "assert 50 < n_tokens < 60"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[' ', 'C', 'K', 'p', 'R', 'E', 'P', 'z', 'd', 'm', 'H', 'M', 'U', 'F', 'r', 'a', 'n', 'f', 'g', 'k', 'B', 'w', 'X', 'i', 'L', 'N', 'h', 'Y', 'e', 'A', 't', 'x', 'y', 'J', 'V', 'u', 's', 'Q', 'W', '#', 'O', 'o', 'l', 'T', \"'\", 'I', 'G', 'q', 'c', 'Z', 'j', 'v', 'S', 'b', 'D', '-']\n",
            "n_tokens: 56\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIzVGM0WbAcC",
        "colab_type": "text"
      },
      "source": [
        "### Cast everything from symbols into identifiers\n",
        "\n",
        "Tensorflow string manipulation is a bit tricky, so we'll work around it. \n",
        "We'll feed our recurrent neural network with ids of characters from our dictionary.\n",
        "\n",
        "To create such dictionary, let's assign `token_to_id`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.870330Z",
          "start_time": "2018-08-13T20:26:42.866135Z"
        },
        "id": "Vd6mbAj6bAcD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "token_to_id = {item :tokens.index(item) for item in tokens} ### YOUR CODE HERE: create a dictionary of {symbol -> its  index in tokens}\n",
        "\n",
        "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.875943Z",
          "start_time": "2018-08-13T20:26:42.871834Z"
        },
        "id": "gBkzjKNlbAcH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_matrix(names, max_len=None, pad=token_to_id[pad_token], dtype=np.int32):\n",
        "    \"\"\"Casts a list of names into rnn-digestable padded matrix\"\"\"\n",
        "    \n",
        "    max_len = max_len or max(map(len, names))\n",
        "    names_ix = np.zeros([len(names), max_len], dtype) + pad\n",
        "\n",
        "    for i in range(len(names)):\n",
        "        name_ix = list(map(token_to_id.get, names[i]))\n",
        "        names_ix[i, :len(name_ix)] = name_ix\n",
        "\n",
        "    return names_ix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.883107Z",
          "start_time": "2018-08-13T20:26:42.877186Z"
        },
        "id": "I4YeX0xEbAcK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "058a6428-92f5-4e38-a009-5568640da17a"
      },
      "source": [
        "# Example: cast 4 random names to padded matrices (so that we can easily batch them)\n",
        "print('\\n'.join(names[::2000]))\n",
        "print(to_matrix(names[::2000]))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Abagael\n",
            " Glory\n",
            " Prissie\n",
            " Giovanne\n",
            "[[ 0 29 53 15 18 15 28 42 39]\n",
            " [ 0 46 42 41 14 32 39 39 39]\n",
            " [ 0  6 14 23 36 36 23 28 39]\n",
            " [ 0 46 23 41 51 15 16 16 28]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h16dOsipbAcO",
        "colab_type": "text"
      },
      "source": [
        "# Defining a recurrent neural network\n",
        "\n",
        "We can rewrite recurrent neural network as a consecutive application of dense layer to input $x_t$ and previous rnn state $h_t$. This is exactly what we're gonna do now.\n",
        "<img src=\"https://github.com/hse-aml/intro-to-dl/blob/master/week5/rnn.png?raw=1\" width=600>\n",
        "\n",
        "Since we're training a language model, there should also be:\n",
        "* An embedding layer that converts character id x_t to a vector.\n",
        "* An output layer that predicts probabilities of next phoneme based on h_t+1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.039419Z",
          "start_time": "2018-08-13T20:26:42.884581Z"
        },
        "id": "hbe1v8FQbAcO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "d53acf92-5ef8-46bd-c2e2-f2b38c69f4fa"
      },
      "source": [
        "# remember to reset your session if you change your graph!\n",
        "s = keras_utils.reset_tf_session()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/keras_utils.py:68: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:79: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:82: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:84: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/keras_utils.py:75: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/keras_utils.py:77: The name tf.InteractiveSession is deprecated. Please use tf.compat.v1.InteractiveSession instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.044903Z",
          "start_time": "2018-08-13T20:26:44.041084Z"
        },
        "id": "tLl6Rk0TbAcR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.layers import concatenate, Dense, Embedding\n",
        "\n",
        "rnn_num_units = 64  # size of hidden state\n",
        "embedding_size = 16  # for characters\n",
        "\n",
        "# Let's create layers for our recurrent network\n",
        "# Note: we create layers but we don't \"apply\" them yet (this is a \"functional API\" of Keras)\n",
        "# Note: set the correct activation (from keras.activations) to Dense layers!\n",
        "\n",
        "# an embedding layer that converts character ids into embeddings\n",
        "embed_x = Embedding(n_tokens, embedding_size)\n",
        "\n",
        "# a dense layer that maps input and previous state to new hidden state, [x_t,h_t]->h_t+1\n",
        "get_h_next = Dense(rnn_num_units, activation='tanh')\n",
        "\n",
        "# a dense layer that maps current hidden state to probabilities of characters [h_t+1]->P(x_t+1|h_t+1)\n",
        "get_probas = Dense(n_tokens, activation='softmax')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nnfOmg0bAcW",
        "colab_type": "text"
      },
      "source": [
        "We will generate names character by character starting with `start_token`:\n",
        "\n",
        "<img src=\"https://github.com/hse-aml/intro-to-dl/blob/master/week5/char-nn.png?raw=1\" width=600>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.053212Z",
          "start_time": "2018-08-13T20:26:44.048389Z"
        },
        "id": "B9CjmyeVbAcW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rnn_one_step(x_t, h_t):\n",
        "    \"\"\"\n",
        "    Recurrent neural network step that produces \n",
        "    probabilities for next token x_t+1 and next state h_t+1\n",
        "    given current input x_t and previous state h_t.\n",
        "    We'll call this method repeatedly to produce the whole sequence.\n",
        "    \n",
        "    You're supposed to \"apply\" above layers to produce new tensors.\n",
        "    Follow inline instructions to complete the function.\n",
        "    \"\"\"\n",
        "    # convert character id into embedding\n",
        "    x_t_emb = embed_x(tf.reshape(x_t, [-1, 1]))[:, 0]\n",
        "    \n",
        "    # concatenate x_t embedding and previous h_t state\n",
        "    x_and_h = concatenate([x_t_emb, h_t]) ### YOUR CODE HERE\n",
        "    \n",
        "    # compute next state given x_and_h\n",
        "    h_next = get_h_next(x_and_h) ### YOUR CODE HERE\n",
        "    \n",
        "    # get probabilities for language model P(x_next|h_next)\n",
        "    output_probas = get_probas(h_next) ### YOUR CODE HERE\n",
        "    \n",
        "    return output_probas, h_next"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O04hExGLbAcZ",
        "colab_type": "text"
      },
      "source": [
        "# RNN: loop\n",
        "\n",
        "Once `rnn_one_step` is ready, let's apply it in a loop over name characters to get predictions.\n",
        "\n",
        "Let's assume that all names are at most length-16 for now, so we can simply iterate over them in a for loop.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.342948Z",
          "start_time": "2018-08-13T20:26:44.056136Z"
        },
        "id": "NUlJcRHQbAca",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "9359dff0-5150-4249-83fd-7d6731ad20e4"
      },
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, MAX_LENGTH))  # batch of token ids\n",
        "batch_size = tf.shape(input_sequence)[0]\n",
        "\n",
        "predicted_probas = []\n",
        "h_prev = tf.zeros([batch_size, rnn_num_units])  # initial hidden state\n",
        "\n",
        "for t in range(MAX_LENGTH):\n",
        "    x_t = input_sequence[:, t]  # column t\n",
        "    probas_next, h_next = rnn_one_step(x_t, h_prev)\n",
        "    \n",
        "    h_prev = h_next\n",
        "    predicted_probas.append(probas_next)\n",
        "    \n",
        "# combine predicted_probas into [batch, time, n_tokens] tensor\n",
        "predicted_probas = tf.transpose(tf.stack(predicted_probas), [1, 0, 2])\n",
        "\n",
        "# next to last token prediction is not needed\n",
        "predicted_probas = predicted_probas[:, :-1, :]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3535: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hW7TXPkBbAcd",
        "colab_type": "text"
      },
      "source": [
        "# RNN: loss and gradients\n",
        "\n",
        "Let's gather a matrix of predictions for $P(x_{next}|h)$ and the corresponding correct answers.\n",
        "\n",
        "We will flatten our matrices to shape [None, n_tokens] to make it easier.\n",
        "\n",
        "Our network can then be trained by minimizing crossentropy between predicted probabilities and those answers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.354310Z",
          "start_time": "2018-08-13T20:26:44.344648Z"
        },
        "id": "fZl3YtoCbAcd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# flatten predictions to [batch*time, n_tokens]\n",
        "predictions_matrix = tf.reshape(predicted_probas, [-1, n_tokens])\n",
        "\n",
        "# flatten answers (next tokens) and one-hot encode them\n",
        "answers_matrix = tf.one_hot(tf.reshape(input_sequence[:, 1:], [-1]), n_tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOb0PRrMbAci",
        "colab_type": "text"
      },
      "source": [
        "Usually it's a good idea to ignore gradients of loss for padding token predictions.\n",
        "\n",
        "Because we don't care about further prediction after the pad_token is predicted for the first time, so it doesn't make sense to punish our network after the pad_token is predicted.\n",
        "\n",
        "For simplicity you can ignore this comment, it's up to you."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:45.076642Z",
          "start_time": "2018-08-13T20:26:44.355594Z"
        },
        "id": "wQ9fgQIFbAcj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the loss as categorical cross-entropy (e.g. from keras.losses).\n",
        "# Mind that predictions are probabilities and NOT logits!\n",
        "# Remember to apply tf.reduce_mean to get a scalar loss!\n",
        "loss = -tf.reduce_mean(answers_matrix * tf.log(predictions_matrix)) ### YOUR CODE HERE\n",
        "\n",
        "optimize = tf.train.AdamOptimizer().minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuYowuWtbAcm",
        "colab_type": "text"
      },
      "source": [
        "# RNN: training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.322187Z",
          "start_time": "2018-08-13T20:26:45.078296Z"
        },
        "id": "_hNE9GvvbAcm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "a1fb2f3d-6f5f-49c1-9f3e-c1a65ec879e4"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "from random import sample\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "batch_size = 32\n",
        "history = []\n",
        "\n",
        "for i in range(1000):\n",
        "    batch = to_matrix(sample(names, batch_size), max_len=MAX_LENGTH)\n",
        "    loss_i, _ = s.run([loss, optimize], {input_sequence: batch})\n",
        "    \n",
        "    history.append(loss_i)\n",
        "    \n",
        "    if (i + 1) % 100 == 0:\n",
        "        clear_output(True)\n",
        "        plt.plot(history, label='loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge\""
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mkwi9_srbAcr",
        "colab_type": "text"
      },
      "source": [
        "# RNN: sampling\n",
        "Once we've trained our network a bit, let's get to actually generating stuff. All we need is the `rnn_one_step` function you have written above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.341196Z",
          "start_time": "2018-08-13T20:26:55.323787Z"
        },
        "id": "qBVAvXVhbAcr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_t = tf.placeholder(tf.int32, (1,))\n",
        "h_t = tf.Variable(np.zeros([1, rnn_num_units], np.float32))  # we will update hidden state in this variable\n",
        "\n",
        "# For sampling we need to define `rnn_one_step` tensors only once in our graph.\n",
        "# We reuse all parameters thanks to functional API usage.\n",
        "# Then we can feed appropriate tensor values using feed_dict in a loop.\n",
        "# Note how different it is from training stage, where we had to unroll the whole sequence for backprop.\n",
        "next_probs, next_h = rnn_one_step(x_t, h_t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.346422Z",
          "start_time": "2018-08-13T20:26:55.342659Z"
        },
        "id": "I8oUjDRKbAcv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_sample(seed_phrase=start_token, max_length=MAX_LENGTH):\n",
        "    '''\n",
        "    This function generates text given a `seed_phrase` as a seed.\n",
        "    Remember to include start_token in seed phrase!\n",
        "    Parameter `max_length` is used to set the number of characters in prediction.\n",
        "    '''\n",
        "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
        "    s.run(tf.assign(h_t, h_t.initial_value))\n",
        "    \n",
        "    # feed the seed phrase, if any\n",
        "    for ix in x_sequence[:-1]:\n",
        "         s.run(tf.assign(h_t, next_h), {x_t: [ix]})\n",
        "    \n",
        "    # start generating\n",
        "    for _ in range(max_length-len(seed_phrase)):\n",
        "        x_probs,_ = s.run([next_probs, tf.assign(h_t, next_h)], {x_t: [x_sequence[-1]]})\n",
        "        x_sequence.append(np.random.choice(n_tokens, p=x_probs[0]))\n",
        "        \n",
        "    return ''.join([tokens[ix] for ix in x_sequence if tokens[ix] != pad_token])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:58.458115Z",
          "start_time": "2018-08-13T20:26:55.347900Z"
        },
        "id": "rf6FviYpbAcy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "496eadd7-aa14-4271-b30d-e0bac60b1453"
      },
      "source": [
        "# without prefix\n",
        "for _ in range(10):\n",
        "    print(generate_sample())"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Ponie\n",
            " Martie\n",
            " Lanry\n",
            " Srdlheltes\n",
            " Rerklal\n",
            " Nuriil\n",
            " Bala\n",
            " Cajel\n",
            " Ripthha\n",
            " Kaleliut\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:01.986726Z",
          "start_time": "2018-08-13T20:26:58.459810Z"
        },
        "id": "l9GrCo21bAc2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "c59c2053-ce91-4c4f-dee4-adcb2b29cbb6"
      },
      "source": [
        "# with prefix conditioning\n",
        "for _ in range(10):\n",
        "    print(generate_sample(' Trump'))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Trump\n",
            " Trumpld\n",
            " Trumpia\n",
            " Trumpe\n",
            " Trumpire\n",
            " Trumpe\n",
            " Trump\n",
            " Trumpee\n",
            " Trumpela\n",
            " Trumpe\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obPskNbobAc4",
        "colab_type": "text"
      },
      "source": [
        "# Submit to Coursera"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:40:02.004926Z",
          "start_time": "2018-08-13T20:40:02.000821Z"
        },
        "id": "XPVCzQtkbAc5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# token expires every 30 min\n",
        "COURSERA_TOKEN = \"0AQigFl9KjeyXmFL\"\n",
        "COURSERA_EMAIL = \"ahmedabdulhamid2000@gmail.com\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:40:18.923357Z",
          "start_time": "2018-08-13T20:40:03.549343Z"
        },
        "id": "Nc7mMThYbAc8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "30a34518-2a86-4401-f233-a068bfcc498f"
      },
      "source": [
        "from submit import submit_char_rnn\n",
        "samples = [generate_sample(' Al') for i in tqdm_utils.tqdm_notebook_failsafe(range(25))]\n",
        "submission = (history, samples)\n",
        "submit_char_rnn(submission, COURSERA_EMAIL, COURSERA_TOKEN)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*************************\n",
            "\n",
            "Submitted to Coursera platform. See results on assignment page!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5nJRM1ubAc_",
        "colab_type": "text"
      },
      "source": [
        "# Try it out!\n",
        "\n",
        "__Disclaimer:__ This part of assignment is entirely optional. You won't receive bonus points for it. However, it's a fun thing to do. Please share your results on course forums.\n",
        "\n",
        "You've just implemented a recurrent language model that can be tasked with generating any kind of sequence, so there's plenty of data you can try it on:\n",
        "\n",
        "* Novels/poems/songs of your favorite author\n",
        "* News titles/clickbait titles\n",
        "* Source code of Linux or Tensorflow\n",
        "* Molecules in [smiles](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) format\n",
        "* Melody in notes/chords format\n",
        "* IKEA catalog titles\n",
        "* Pokemon names\n",
        "* Cards from Magic, the Gathering / Hearthstone\n",
        "\n",
        "If you're willing to give it a try, here's what you wanna look at:\n",
        "* Current data format is a sequence of lines, so a novel can be formatted as a list of sentences. Alternatively, you can change data preprocessing altogether.\n",
        "* While some datasets are readily available, others can only be scraped from the web. Try `Selenium` or `Scrapy` for that.\n",
        "* Make sure MAX_LENGTH is adjusted for longer datasets. There's also a bonus section about dynamic RNNs at the bottom.\n",
        "* More complex tasks require larger RNN architecture, try more neurons or several layers. It would also require more training iterations.\n",
        "* Long-term dependencies in music, novels or molecules are better handled with LSTM or GRU\n",
        "\n",
        "__Good hunting!__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "rcSVEFalbAdA",
        "colab_type": "text"
      },
      "source": [
        "# Bonus level: dynamic RNNs\n",
        "\n",
        "Apart from Keras, there's also a friendly TensorFlow API for recurrent neural nets. It's based around the symbolic loop function (aka [tf.scan](https://www.tensorflow.org/api_docs/python/tf/scan)).\n",
        "\n",
        "RNN loop that we implemented for training can be replaced with single TensorFlow instruction: [tf.nn.dynamic_rnn](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn).\n",
        "This interface allows for dynamic sequence length and comes with some pre-implemented architectures.\n",
        "\n",
        "Take a look at [tf.nn.rnn_cell.BasicRNNCell](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicRNNCell)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.975354Z",
          "start_time": "2018-08-13T20:27:12.737529Z"
        },
        "id": "0_KNWvzRbAdB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CustomRNN(tf.nn.rnn_cell.BasicRNNCell):\n",
        "    def call(self, input, state):\n",
        "        # from docs:\n",
        "        # Returns:\n",
        "        # Output: A 2-D tensor with shape [batch_size, self.output_size].\n",
        "        # New state: Either a single 2-D tensor, or a tuple of tensors matching the arity and shapes of state.\n",
        "        return rnn_one_step(input[:, 0], state)\n",
        "    \n",
        "    @property\n",
        "    def output_size(self):\n",
        "        return n_tokens\n",
        "    \n",
        "cell = CustomRNN(rnn_num_units)\n",
        "\n",
        "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
        "    \n",
        "predicted_probas, last_state = tf.nn.dynamic_rnn(cell, input_sequence[:, :, None], dtype=tf.float32)\n",
        "\n",
        "print('LSTM outputs for each step [batch,time,n_tokens]:')\n",
        "print(predicted_probas.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9W3BOpmbAdF",
        "colab_type": "text"
      },
      "source": [
        "Note that we never used MAX_LENGTH in the code above: TF will iterate over however many time-steps you gave it.\n",
        "\n",
        "You can also use any pre-implemented RNN cell:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.981697Z",
          "start_time": "2018-08-13T20:27:12.977590Z"
        },
        "id": "grXTF2o4bAdF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for obj in dir(tf.nn.rnn_cell) + dir(tf.contrib.rnn):\n",
        "    if obj.endswith('Cell'):\n",
        "        print(obj, end=\"\\t\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:13.168207Z",
          "start_time": "2018-08-13T20:27:12.986884Z"
        },
        "id": "zwmML4I2bAdJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
        "\n",
        "inputs_embedded = embed_x(input_sequence)\n",
        "\n",
        "# standard cell returns hidden state as output!\n",
        "cell = tf.nn.rnn_cell.LSTMCell(rnn_num_units)\n",
        "\n",
        "state_sequence, last_state = tf.nn.dynamic_rnn(cell, inputs_embedded, dtype=tf.float32)\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "print('LSTM hidden state for each step [batch,time,rnn_num_units]:')\n",
        "print(state_sequence.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}